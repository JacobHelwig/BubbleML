#  parameters: 260378629 (before // 2,   fmode_frac: [0.25, 0.25])
# parameters: 260378629 (after // 2, fmode_frac: [0.5, 0.5])
torch_dataset_name: temp_input_dataset 

# torch distributed does not support complex parameters
distributed: False

train:
  max_epochs: 350 
  batch_size: 4
  shuffle_data: True
  time_window: 5
  future_window: 5
  push_forward_steps: 1
  use_coords: True
  noise: True
  downsample_factor: 4 

model:
  model_name: gfno
  fmode_frac: [0.5, 0.5] # [0.25, 0.25]
  width: 64
  reflection: False
  domain_padding: 0

optimizer:
  initial_lr: 1e-3
  weight_decay: 1e-6

lr_scheduler:
  name: cosine
  eta_min: 1e-6 # NEW